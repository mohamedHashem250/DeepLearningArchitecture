{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFxPzZ-He11b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTvfZ54e8xR",
        "outputId": "9e4dea7e-36ed-4919-f74d-c19a49bb6b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz_KvguZfHwY",
        "outputId": "59655633-f7a7-4332-aa01-ab2c69a02e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#laod the test dataset MNIST Data:\n",
        "PATH =  '/content/drive/MyDrive/NeuroTech/Preparation_Sun_Wednesday/FifthSession/'\n",
        "test_dataset = pickle.load(open(PATH +\"test_dataset.pkl\",\"rb\"))"
      ],
      "metadata": {
        "id": "yJm_NLgIfHzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "pD9QjbekfLvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the scripted model\n",
        "preTrained_model = torch.jit.load(PATH + \"traced_model.pt\")"
      ],
      "metadata": {
        "id": "zfN21AdUfLx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Good link: https://medium.com/octavian-ai/a-simple-explanation-of-the-inception-score-372dff6a8c7a\n",
        "def IS(probs):\n",
        "  #calculate marginal probability p(y)\n",
        "  p_y = torch.mean(probs, axis = 0)#for each class\n",
        "  #calculate k_l KL divergence for each outcome\n",
        "  kl_div = torch.sum( probs * torch.log(probs / p_y), axis = 1)#just for showing\n",
        "  #calculate IS\n",
        "  inception_score = torch.exp(kl_div.mean())\n",
        "  return inception_score\n",
        "\n",
        "\n",
        "def MNIST_Classifier_Score(model , generated_images , n_splits = 10):\n",
        "  #this function try to mimic Inception score function to assess the generative models like GAN:\n",
        "  #to measure diversity and quality of generated MNIST daata\n",
        "  #so we need to leverage from our classifier to assess these architectures.\n",
        "  #note our classifier accuray reach to 97.8% , so it may be authentic to do this task!\n",
        "  ################################\n",
        "  ###### Prediction Step #########\n",
        "  ################################\n",
        "  test_loader = DataLoader(generated_images, batch_size=64)\n",
        "  y_pred = []\n",
        "  with torch.no_grad():\n",
        "      for features, target in test_loader:\n",
        "        features, labels = features.to(device), target.to(device)\n",
        "        logits, y_hat = model(features)\n",
        "        y_pred.extend(y_hat)\n",
        "  ################################\n",
        "  ###### Calculate IS ############\n",
        "  ################################\n",
        "\n",
        "  print(\"no of prediction output: \", torch.stack(y_pred).shape)\n",
        "  print( \"no of Split Batches  : \", int(len(y_pred)/n_splits))\n",
        "  labels_batches = torch.split(torch.stack(y_pred), int(len(y_pred)/n_splits))#divide labels predictions to chunks based on n-splits\n",
        "  Is_s = np.array([IS(probs).cpu().numpy() for probs in labels_batches])\n",
        "  return Is_s.mean() , Is_s.std()\n",
        "\n"
      ],
      "metadata": {
        "id": "719w5NjWe8zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's try on test dataset :10,000:\n",
        "m , s = MNIST_Classifier_Score(model = preTrained_model, generated_images = test_dataset  , n_splits = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j822fuUQe82Q",
        "outputId": "b7002512-beba-4fce-d919-beef5b52fcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of prediction output:  torch.Size([10000, 10])\n",
            "no of Split Batches  :  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m,s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gusrOpjke83_",
        "outputId": "41408e8a-f41d-461e-ae27-d39e342fb26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float32(9.713059), np.float32(0.09543667))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}